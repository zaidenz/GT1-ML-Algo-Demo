{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ü§ñ Advanced ML Trading System Demo\n",
    "## Professional Algorithmic Trading with Machine Learning\n",
    "\n",
    "**System Overview:** Multi-model ensemble trading system using advanced feature engineering and time series ML  \n",
    "**Performance Target:** Enhanced risk-adjusted returns through adaptive market pattern recognition  \n",
    "**Technology Stack:** Python, XGBoost, LightGBM, Custom Technical Analysis, Time Series Cross-Validation  \n",
    "\n",
    "---\n",
    "\n",
    "### üéØ **Key Features:**\n",
    "- **50+ Advanced Features** from market microstructure analysis\n",
    "- **Ensemble ML Models** with time-aware cross-validation\n",
    "- **Custom Technical Indicators** for enhanced signal quality\n",
    "- **Risk Management Integration** with position sizing\n",
    "- **Production-Ready Architecture** for live deployment\n",
    "\n",
    "*Note: This demo shows system architecture and capabilities. Proprietary features and specific trading logic are abstracted for IP protection.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ System Setup & Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from datetime import datetime, timedelta\n",
    "import yfinance as yf\n",
    "\n",
    "# ML Libraries\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "import xgboost as xgb\n",
    "\n",
    "# Configure visualization\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"üöÄ ML Trading System Initialized\")\n",
    "print(f\"üìä Environment Ready - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Market Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Professional data loading with error handling\n",
    "def load_market_data(ticker=\"QQQ\", period_days=365):\n",
    "    \"\"\"\n",
    "    Load market data with robust error handling and validation\n",
    "    \"\"\"\n",
    "    try:\n",
    "        end_date = datetime.now()\n",
    "        start_date = end_date - timedelta(days=period_days)\n",
    "        \n",
    "        print(f\"üì• Loading {ticker} data ({period_days} days)...\")\n",
    "        df = yf.download(ticker, start=start_date, end=end_date, interval=\"1d\")\n",
    "        \n",
    "        # Handle MultiIndex columns from yfinance\n",
    "        if isinstance(df.columns, pd.MultiIndex):\n",
    "            df.columns = [col[0].lower() if isinstance(col, tuple) else col.lower() for col in df.columns]\n",
    "        else:\n",
    "            df.columns = [col.lower() for col in df.columns]\n",
    "        \n",
    "        # Data validation\n",
    "        df = df.dropna()\n",
    "        \n",
    "        print(f\"‚úÖ Data loaded: {len(df)} records\")\n",
    "        print(f\"üìÖ Period: {df.index[0].date()} to {df.index[-1].date()}\")\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Data loading failed: {e}\")\n",
    "        return None\n",
    "\n",
    "# Load demonstration data\n",
    "df = load_market_data(\"QQQ\", 500)  # NASDAQ ETF for demo\n",
    "\n",
    "if df is not None:\n",
    "    print(f\"\\nüìà Price Summary:\")\n",
    "    print(f\"   Range: ${df['close'].min():.2f} - ${df['close'].max():.2f}\")\n",
    "    print(f\"   Latest: ${df['close'].iloc[-1]:.2f}\")\n",
    "    \n",
    "    # Display sample\n",
    "    df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Advanced Feature Engineering Framework\n",
    "\n",
    "**Professional ML feature extraction pipeline with 50+ indicators:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvancedFeatureExtractor:\n",
    "    \"\"\"\n",
    "    Professional-grade feature extraction for trading systems\n",
    "    Implements market microstructure, technical, and behavioral features\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.scaler = StandardScaler()\n",
    "        print(\"üîß Advanced Feature Extractor Initialized\")\n",
    "        \n",
    "    def extract_features(self, df):\n",
    "        \"\"\"\n",
    "        Extract comprehensive feature set for ML models\n",
    "        \"\"\"\n",
    "        features = pd.DataFrame(index=df.index)\n",
    "        print(\"‚öôÔ∏è Extracting ML features...\")\n",
    "        \n",
    "        # === PRICE ACTION FEATURES ===\n",
    "        print(\"   üìä Price action analysis...\")\n",
    "        for period in [5, 10, 20, 50]:\n",
    "            features[f'sma_{period}'] = df['close'].rolling(period).mean()\n",
    "            features[f'price_to_sma_{period}'] = df['close'] / features[f'sma_{period}']\n",
    "            features[f'volatility_{period}'] = df['close'].rolling(period).std()\n",
    "        \n",
    "        # === MOMENTUM INDICATORS ===\n",
    "        print(\"   ‚ö° Momentum analysis...\")\n",
    "        for period in [1, 3, 5, 10, 20]:\n",
    "            features[f'return_{period}d'] = df['close'].pct_change(period)\n",
    "            features[f'momentum_{period}'] = (df['close'] - df['close'].shift(period)) / df['close'].shift(period)\n",
    "        \n",
    "        # === VOLUME ANALYSIS ===\n",
    "        print(\"   üìà Volume microstructure...\")\n",
    "        features['volume_sma_20'] = df['volume'].rolling(20).mean()\n",
    "        features['volume_ratio'] = df['volume'] / features['volume_sma_20']\n",
    "        features['price_volume'] = df['close'] * df['volume']\n",
    "        features['volume_trend'] = df['volume'].rolling(5).mean() / df['volume'].rolling(20).mean()\n",
    "        \n",
    "        # === RANGE ANALYSIS ===\n",
    "        print(\"   üìè Range and positioning...\")\n",
    "        for period in [10, 20, 50]:\n",
    "            features[f'high_{period}'] = df['high'].rolling(period).max()\n",
    "            features[f'low_{period}'] = df['low'].rolling(period).min()\n",
    "            features[f'range_{period}'] = features[f'high_{period}'] - features[f'low_{period}']\n",
    "            features[f'position_in_range_{period}'] = (df['close'] - features[f'low_{period}']) / features[f'range_{period}']\n",
    "        \n",
    "        # === ADVANCED TECHNICAL INDICATORS ===\n",
    "        print(\"   üéØ Advanced technical analysis...\")\n",
    "        # Custom RSI implementation\n",
    "        def calculate_rsi(prices, period=14):\n",
    "            delta = prices.diff()\n",
    "            gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()\n",
    "            loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()\n",
    "            rs = gain / loss\n",
    "            return 100 - (100 / (1 + rs))\n",
    "        \n",
    "        features['rsi_14'] = calculate_rsi(df['close'], 14)\n",
    "        features['rsi_7'] = calculate_rsi(df['close'], 7)\n",
    "        \n",
    "        # Bollinger Bands\n",
    "        features['bb_middle'] = df['close'].rolling(20).mean()\n",
    "        features['bb_std'] = df['close'].rolling(20).std()\n",
    "        features['bb_upper'] = features['bb_middle'] + (features['bb_std'] * 2)\n",
    "        features['bb_lower'] = features['bb_middle'] - (features['bb_std'] * 2)\n",
    "        features['bb_position'] = (df['close'] - features['bb_lower']) / (features['bb_upper'] - features['bb_lower'])\n",
    "        \n",
    "        # === MARKET TIMING FEATURES ===\n",
    "        print(\"   ‚è∞ Temporal pattern analysis...\")\n",
    "        features['day_of_week'] = df.index.dayofweek\n",
    "        features['hour'] = df.index.hour\n",
    "        features['day_of_month'] = df.index.day\n",
    "        \n",
    "        # Cyclical encoding for time features\n",
    "        features['dow_sin'] = np.sin(2 * np.pi * features['day_of_week'] / 7)\n",
    "        features['dow_cos'] = np.cos(2 * np.pi * features['day_of_week'] / 7)\n",
    "        \n",
    "        # === PROPRIETARY FEATURES (ABSTRACTED) ===\n",
    "        print(\"   üîí Proprietary signal processing...\")\n",
    "        # Note: Actual proprietary features are abstracted for IP protection\n",
    "        features['custom_signal_1'] = np.random.normal(0, 1, len(df))  # Placeholder\n",
    "        features['custom_signal_2'] = np.random.normal(0, 1, len(df))  # Placeholder\n",
    "        features['custom_timing'] = np.random.choice([0, 1], len(df), p=[0.9, 0.1])  # Placeholder\n",
    "        \n",
    "        # === TARGET VARIABLES ===\n",
    "        print(\"   üéØ Target variable creation...\")\n",
    "        for horizon in [1, 5, 10, 20]:\n",
    "            features[f'forward_return_{horizon}'] = df['close'].shift(-horizon) / df['close'] - 1\n",
    "            features[f'target_up_{horizon}'] = (features[f'forward_return_{horizon}'] > 0).astype(int)\n",
    "        \n",
    "        print(f\"‚úÖ Feature extraction complete: {len(features.columns)} features\")\n",
    "        return features.dropna()\n",
    "    \n",
    "    def prepare_ml_data(self, features_df, target_col='forward_return_5'):\n",
    "        \"\"\"\n",
    "        Prepare features and targets for ML training\n",
    "        \"\"\"\n",
    "        # Separate features from targets\n",
    "        feature_cols = [col for col in features_df.columns \n",
    "                       if not col.startswith('forward_return') and not col.startswith('target_up')]\n",
    "        \n",
    "        X = features_df[feature_cols]\n",
    "        y = features_df[target_col]\n",
    "        \n",
    "        # Remove NaN values\n",
    "        valid_idx = ~y.isna()\n",
    "        X = X[valid_idx]\n",
    "        y = y[valid_idx]\n",
    "        \n",
    "        return X, y\n",
    "\n",
    "# Initialize and run feature extraction\n",
    "if df is not None:\n",
    "    extractor = AdvancedFeatureExtractor()\n",
    "    features_df = extractor.extract_features(df)\n",
    "    \n",
    "    print(f\"\\nüìä Feature Engineering Results:\")\n",
    "    print(f\"   Samples: {len(features_df)}\")\n",
    "    print(f\"   Features: {len(features_df.columns)}\")\n",
    "    print(f\"   Date Range: {features_df.index[0].date()} to {features_df.index[-1].date()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü§ñ ML Model Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProfessionalMLTrainer:\n",
    "    \"\"\"\n",
    "    Enterprise-grade ML training pipeline for trading systems\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.models = {}\n",
    "        self.feature_importance = {}\n",
    "        print(\"ü§ñ Professional ML Trainer Initialized\")\n",
    "        \n",
    "    def train_ensemble(self, X, y, task_type='regression'):\n",
    "        \"\"\"\n",
    "        Train ensemble of ML models with time series validation\n",
    "        \"\"\"\n",
    "        print(f\"\\nüöÄ Training {task_type} ensemble...\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        # Time series cross-validation\n",
    "        tscv = TimeSeriesSplit(n_splits=5)\n",
    "        \n",
    "        # Model configurations\n",
    "        if task_type == 'regression':\n",
    "            models_config = {\n",
    "                'xgboost': xgb.XGBRegressor(\n",
    "                    n_estimators=100,\n",
    "                    learning_rate=0.1,\n",
    "                    max_depth=6,\n",
    "                    random_state=42,\n",
    "                    verbosity=0\n",
    "                ),\n",
    "                'random_forest': RandomForestRegressor(\n",
    "                    n_estimators=50,\n",
    "                    max_depth=10,\n",
    "                    random_state=42\n",
    "                )\n",
    "            }\n",
    "        else:  # classification\n",
    "            models_config = {\n",
    "                'xgboost': xgb.XGBClassifier(\n",
    "                    n_estimators=100,\n",
    "                    learning_rate=0.1,\n",
    "                    max_depth=6,\n",
    "                    random_state=42,\n",
    "                    verbosity=0\n",
    "                ),\n",
    "                'random_forest': RandomForestClassifier(\n",
    "                    n_estimators=50,\n",
    "                    max_depth=10,\n",
    "                    random_state=42\n",
    "                )\n",
    "            }\n",
    "        \n",
    "        results = {}\n",
    "        for name, model in models_config.items():\n",
    "            print(f\"üìà Training {name}...\")\n",
    "            \n",
    "            try:\n",
    "                # Cross-validation\n",
    "                if task_type == 'regression':\n",
    "                    cv_scores = cross_val_score(model, X, y, cv=tscv, scoring='neg_mean_squared_error')\n",
    "                    score = -cv_scores.mean()\n",
    "                    metric = 'RMSE'\n",
    "                else:\n",
    "                    cv_scores = cross_val_score(model, X, y, cv=tscv, scoring='accuracy')\n",
    "                    score = cv_scores.mean()\n",
    "                    metric = 'Accuracy'\n",
    "                \n",
    "                # Fit final model\n",
    "                model.fit(X, y)\n",
    "                self.models[f\"{task_type}_{name}\"] = model\n",
    "                \n",
    "                # Feature importance\n",
    "                if hasattr(model, 'feature_importances_'):\n",
    "                    importance_dict = dict(zip(X.columns, model.feature_importances_))\n",
    "                    self.feature_importance[f\"{task_type}_{name}\"] = importance_dict\n",
    "                \n",
    "                results[name] = {\n",
    "                    'score': score,\n",
    "                    'std': cv_scores.std(),\n",
    "                    'metric': metric\n",
    "                }\n",
    "                \n",
    "                print(f\"‚úÖ {name}: {metric} = {score:.4f} (¬±{cv_scores.std():.4f})\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå {name}: Training failed - {str(e)}\")\n",
    "                results[name] = {'score': 0, 'std': 0, 'metric': 'Error'}\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def analyze_features(self, top_n=15):\n",
    "        \"\"\"\n",
    "        Analyze feature importance across models\n",
    "        \"\"\"\n",
    "        if not self.feature_importance:\n",
    "            print(\"No feature importance data available\")\n",
    "            return []\n",
    "        \n",
    "        # Aggregate importance across models\n",
    "        all_importance = {}\n",
    "        for model_name, importance_dict in self.feature_importance.items():\n",
    "            for feature, importance in importance_dict.items():\n",
    "                if feature not in all_importance:\n",
    "                    all_importance[feature] = []\n",
    "                all_importance[feature].append(importance)\n",
    "        \n",
    "        # Average importance\n",
    "        avg_importance = {\n",
    "            feature: np.mean(importances)\n",
    "            for feature, importances in all_importance.items()\n",
    "        }\n",
    "        \n",
    "        # Sort by importance\n",
    "        sorted_features = sorted(avg_importance.items(), key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        print(f\"\\nüìä TOP {top_n} MOST IMPORTANT FEATURES:\")\n",
    "        print(\"=\" * 60)\n",
    "        for i, (feature, importance) in enumerate(sorted_features[:top_n], 1):\n",
    "            print(f\"{i:2d}. {feature:<25} {importance:.4f}\")\n",
    "        \n",
    "        return sorted_features\n",
    "\n",
    "# Train models if features are available\n",
    "if 'features_df' in locals() and not features_df.empty:\n",
    "    # Prepare training data\n",
    "    X, y = extractor.prepare_ml_data(features_df, target_col='forward_return_5')\n",
    "    \n",
    "    print(f\"\\nüìã Training Data Prepared:\")\n",
    "    print(f\"   Samples: {len(X)}\")\n",
    "    print(f\"   Features: {len(X.columns)}\")\n",
    "    print(f\"   Target Mean: {y.mean():.4f}\")\n",
    "    \n",
    "    # Initialize trainer and train models\n",
    "    trainer = ProfessionalMLTrainer()\n",
    "    \n",
    "    # Train regression models\n",
    "    reg_results = trainer.train_ensemble(X, y, task_type='regression')\n",
    "    \n",
    "    # Analyze feature importance\n",
    "    important_features = trainer.analyze_features(top_n=20)\n",
    "    \n",
    "    print(f\"\\nüéâ ML Training Complete!\")\n",
    "else:\n",
    "    print(\"‚ùå No feature data available for training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Feature Importance Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature importance\n",
    "if 'important_features' in locals() and important_features:\n",
    "    # Get top features for visualization\n",
    "    top_features = important_features[:12]\n",
    "    feature_names = [f[0] for f in top_features]\n",
    "    feature_scores = [f[1] for f in top_features]\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    bars = plt.barh(range(len(feature_names)), feature_scores, color='steelblue')\n",
    "    plt.yticks(range(len(feature_names)), feature_names)\n",
    "    plt.xlabel('Feature Importance')\n",
    "    plt.title('üéØ Top ML Features for Trading System', fontsize=16, fontweight='bold')\n",
    "    plt.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, bar in enumerate(bars):\n",
    "        width = bar.get_width()\n",
    "        plt.text(width + 0.001, bar.get_y() + bar.get_height()/2, \n",
    "                f'{width:.3f}', ha='left', va='center', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nüîç Feature Analysis Summary:\")\n",
    "    print(f\"   Most Important: {important_features[0][0]} ({important_features[0][1]:.4f})\")\n",
    "    print(f\"   Technical Features: {len([f for f in important_features if any(x in f[0] for x in ['sma', 'rsi', 'bb'])])}\")\n",
    "    print(f\"   Volume Features: {len([f for f in important_features if 'volume' in f[0]])}\")\n",
    "    print(f\"   Timing Features: {len([f for f in important_features if any(x in f[0] for x in ['hour', 'dow', 'custom'])])}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Feature importance data not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Signal Generation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProfessionalSignalGenerator:\n",
    "    \"\"\"\n",
    "    Production-grade signal generation system\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, trainer):\n",
    "        self.trainer = trainer\n",
    "        self.models = trainer.models\n",
    "        print(\"üéØ Professional Signal Generator Initialized\")\n",
    "    \n",
    "    def generate_ensemble_predictions(self, X, task_type='regression'):\n",
    "        \"\"\"\n",
    "        Generate ensemble predictions from trained models\n",
    "        \"\"\"\n",
    "        predictions = {}\n",
    "        \n",
    "        for model_name, model in self.models.items():\n",
    "            if not model_name.startswith(task_type):\n",
    "                continue\n",
    "            \n",
    "            name = model_name.replace(f\"{task_type}_\", \"\")\n",
    "            \n",
    "            try:\n",
    "                predictions[name] = model.predict(X)\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Model {name} prediction failed: {e}\")\n",
    "        \n",
    "        if not predictions:\n",
    "            return np.zeros(len(X))\n",
    "        \n",
    "        # Simple ensemble average\n",
    "        ensemble_pred = np.zeros(len(X))\n",
    "        for name, pred in predictions.items():\n",
    "            ensemble_pred += pred / len(predictions)\n",
    "        \n",
    "        return ensemble_pred\n",
    "    \n",
    "    def generate_trading_signals(self, features_df, threshold=0.01):\n",
    "        \"\"\"\n",
    "        Generate professional trading signals\n",
    "        \"\"\"\n",
    "        print(f\"ü§ñ Generating trading signals (threshold: {threshold})...\")\n",
    "        \n",
    "        # Prepare features\n",
    "        feature_cols = [col for col in features_df.columns \n",
    "                       if not col.startswith('forward_return') and not col.startswith('target_up')]\n",
    "        X = features_df[feature_cols]\n",
    "        \n",
    "        # Get predictions\n",
    "        predictions = self.generate_ensemble_predictions(X, task_type='regression')\n",
    "        \n",
    "        # Create signals dataframe\n",
    "        signals = pd.DataFrame(index=features_df.index)\n",
    "        signals['ml_prediction'] = predictions\n",
    "        signals['signal_strength'] = np.abs(predictions)\n",
    "        \n",
    "        # Generate trading signals with risk management\n",
    "        signals['long_signal'] = (\n",
    "            (predictions > threshold) &\n",
    "            (features_df['volume_ratio'] > 1.2) &  # Volume confirmation\n",
    "            (features_df['rsi_14'] < 80)  # Not overbought\n",
    "        )\n",
    "        \n",
    "        signals['short_signal'] = (\n",
    "            (predictions < -threshold) &\n",
    "            (features_df['volume_ratio'] > 1.2) &  # Volume confirmation\n",
    "            (features_df['rsi_14'] > 20)  # Not oversold\n",
    "        )\n",
    "        \n",
    "        # Enhanced signals with proprietary filters (abstracted)\n",
    "        signals['enhanced_long'] = (\n",
    "            signals['long_signal'] &\n",
    "            (features_df['custom_timing'] == 1)  # Proprietary timing (placeholder)\n",
    "        )\n",
    "        \n",
    "        signals['enhanced_short'] = (\n",
    "            signals['short_signal'] &\n",
    "            (features_df['custom_timing'] == 1)  # Proprietary timing (placeholder)\n",
    "        )\n",
    "        \n",
    "        print(f\"‚úÖ Generated {len(signals)} signals\")\n",
    "        return signals\n",
    "\n",
    "# Generate signals if trainer is available\n",
    "if 'trainer' in locals() and 'features_df' in locals():\n",
    "    signal_gen = ProfessionalSignalGenerator(trainer)\n",
    "    signals = signal_gen.generate_trading_signals(features_df, threshold=0.005)\n",
    "    \n",
    "    print(f\"\\nüìä SIGNAL STATISTICS:\")\n",
    "    print(f\"   Total periods: {len(signals)}\")\n",
    "    print(f\"   Long signals: {signals['long_signal'].sum()}\")\n",
    "    print(f\"   Short signals: {signals['short_signal'].sum()}\")\n",
    "    print(f\"   Enhanced long: {signals['enhanced_long'].sum()}\")\n",
    "    print(f\"   Enhanced short: {signals['enhanced_short'].sum()}\")\n",
    "    \n",
    "    # Show sample of enhanced signals\n",
    "    enhanced_signals = signals[signals['enhanced_long'] | signals['enhanced_short']]\n",
    "    if len(enhanced_signals) > 0:\n",
    "        print(f\"\\nüìã SAMPLE ENHANCED SIGNALS:\")\n",
    "        for i, (timestamp, row) in enumerate(enhanced_signals.head(5).iterrows()):\n",
    "            direction = \"LONG\" if row['enhanced_long'] else \"SHORT\"\n",
    "            strength = row['signal_strength']\n",
    "            print(f\"   {i+1}. {timestamp.date()}: {direction:5s} | Strength: {strength:.4f}\")\n",
    "    else:\n",
    "        print(\"\\nüí° No enhanced signals in sample period - adjust threshold for more signals\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Signal generation requires trained models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà Performance Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance visualization\n",
    "if 'signals' in locals() and 'df' in locals():\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "    \n",
    "    # 1. Price chart with signals\n",
    "    axes[0,0].plot(df.index, df['close'], label='Price', linewidth=1)\n",
    "    \n",
    "    # Mark long signals\n",
    "    long_signals = signals[signals['enhanced_long']]\n",
    "    if len(long_signals) > 0:\n",
    "        long_prices = [df.loc[idx, 'close'] for idx in long_signals.index if idx in df.index]\n",
    "        axes[0,0].scatter(long_signals.index, long_prices, \n",
    "                         color='green', marker='^', s=50, label='Long Signals', alpha=0.7)\n",
    "    \n",
    "    # Mark short signals  \n",
    "    short_signals = signals[signals['enhanced_short']]\n",
    "    if len(short_signals) > 0:\n",
    "        short_prices = [df.loc[idx, 'close'] for idx in short_signals.index if idx in df.index]\n",
    "        axes[0,0].scatter(short_signals.index, short_prices,\n",
    "                         color='red', marker='v', s=50, label='Short Signals', alpha=0.7)\n",
    "    \n",
    "    axes[0,0].set_title('üéØ ML Trading Signals', fontweight='bold')\n",
    "    axes[0,0].legend()\n",
    "    axes[0,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Signal distribution\n",
    "    signal_hours = [t.hour for t in signals[signals['enhanced_long'] | signals['enhanced_short']].index]\n",
    "    if signal_hours:\n",
    "        axes[0,1].hist(signal_hours, bins=24, alpha=0.7, color='steelblue')\n",
    "        axes[0,1].set_title('‚è∞ Signal Distribution by Hour')\n",
    "        axes[0,1].set_xlabel('Hour of Day')\n",
    "        axes[0,1].grid(True, alpha=0.3)\n",
    "    else:\n",
    "        axes[0,1].text(0.5, 0.5, 'No signals in sample', ha='center', va='center', transform=axes[0,1].transAxes)\n",
    "        axes[0,1].set_title('‚è∞ Signal Distribution')\n",
    "    \n",
    "    # 3. Prediction accuracy\n",
    "    axes[1,0].hist(signals['ml_prediction'], bins=30, alpha=0.7, color='orange')\n",
    "    axes[1,0].axvline(0, color='red', linestyle='--', alpha=0.7)\n",
    "    axes[1,0].set_title('üé≤ ML Prediction Distribution')\n",
    "    axes[1,0].set_xlabel('Predicted Return')\n",
    "    axes[1,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Signal strength\n",
    "    axes[1,1].plot(signals.index, signals['signal_strength'], alpha=0.7, color='purple')\n",
    "    axes[1,1].set_title('üí™ Signal Strength Over Time')\n",
    "    axes[1,1].set_ylabel('Signal Strength')\n",
    "    axes[1,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nüìä System Performance Summary:\")\n",
    "    print(f\"   Average prediction: {signals['ml_prediction'].mean():.4f}\")\n",
    "    print(f\"   Prediction volatility: {signals['ml_prediction'].std():.4f}\")\n",
    "    print(f\"   Signal rate: {(signals['enhanced_long'].sum() + signals['enhanced_short'].sum()) / len(signals) * 100:.1f}%\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Performance visualization requires signal data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ System Export & Production Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export system for production (demo version)\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "if 'trainer' in locals() and 'signal_gen' in locals():\n",
    "    # Create demo system package\n",
    "    demo_system = {\n",
    "        'version': '1.0.0',\n",
    "        'created': datetime.now().isoformat(),\n",
    "        'description': 'ML Trading System Demo - Professional Implementation',\n",
    "        'models_trained': len(trainer.models),\n",
    "        'features_count': len(X.columns) if 'X' in locals() else 0,\n",
    "        'data_samples': len(features_df) if 'features_df' in locals() else 0,\n",
    "        'config': {\n",
    "            'signal_threshold': 0.005,\n",
    "            'volume_filter': True,\n",
    "            'rsi_bounds': [20, 80],\n",
    "            'ensemble_models': list(trainer.models.keys()) if hasattr(trainer, 'models') else []\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Save demo info (not the actual models for IP protection)\n",
    "    with open('ml_trading_system_demo_info.pkl', 'wb') as f:\n",
    "        pickle.dump(demo_system, f)\n",
    "    \n",
    "    print(\"üíæ DEMO SYSTEM EXPORT COMPLETE\")\n",
    "    print(\"=\" * 40)\n",
    "    print(f\"üìã System Version: {demo_system['version']}\")\n",
    "    print(f\"ü§ñ Models Trained: {demo_system['models_trained']}\")\n",
    "    print(f\"üìä Features: {demo_system['features_count']}\")\n",
    "    print(f\"üìà Data Samples: {demo_system['data_samples']}\")\n",
    "    \n",
    "    print(\"\\nüöÄ PRODUCTION DEPLOYMENT NOTES:\")\n",
    "    print(\"=\" * 40)\n",
    "    print(\"‚úÖ Real-time data pipeline integration required\")\n",
    "    print(\"‚úÖ Risk management layer implementation\")\n",
    "    print(\"‚úÖ Position sizing optimization\")\n",
    "    print(\"‚úÖ Performance monitoring dashboard\")\n",
    "    print(\"‚úÖ Model retraining schedule (monthly recommended)\")\n",
    "    print(\"‚úÖ Proprietary features integration (IP protected)\")\n",
    "    \n",
    "    print(\"\\nüîí IP PROTECTION NOTES:\")\n",
    "    print(\"=\" * 40)\n",
    "    print(\"‚Ä¢ Proprietary timing algorithms abstracted\")\n",
    "    print(\"‚Ä¢ Specific feature engineering techniques protected\")\n",
    "    print(\"‚Ä¢ Model hyperparameters and ensemble weights secured\")\n",
    "    print(\"‚Ä¢ Custom indicators and signals anonymized\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è System export requires trained models\")\n",
    "\n",
    "print(\"\\nüéâ ML TRADING SYSTEM DEMO COMPLETE!\")\n",
    "print(\"\\nüìù This demonstration showcases:\")\n",
    "print(\"   ‚Ä¢ Professional ML pipeline architecture\")\n",
    "print(\"   ‚Ä¢ Advanced feature engineering capabilities\")\n",
    "print(\"   ‚Ä¢ Ensemble model training and validation\")\n",
    "print(\"   ‚Ä¢ Production-ready signal generation\")\n",
    "print(\"   ‚Ä¢ Comprehensive performance analysis\")\n",
    "print(\"\\nüîê Proprietary components abstracted for IP protection\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
