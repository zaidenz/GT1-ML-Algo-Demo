{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🤖 Advanced ML Trading System Demo\n",
    "## Professional Algorithmic Trading with Machine Learning\n",
    "\n",
    "**System Overview:** Multi-model ensemble trading system using advanced feature engineering and time series ML  \n",
    "**Performance Target:** Enhanced risk-adjusted returns through adaptive market pattern recognition  \n",
    "**Technology Stack:** Python, XGBoost, LightGBM, Custom Technical Analysis, Time Series Cross-Validation  \n",
    "\n",
    "---\n",
    "\n",
    "### 🎯 **Key Features:**\n",
    "- **50+ Advanced Features** from market microstructure analysis\n",
    "- **Ensemble ML Models** with time-aware cross-validation\n",
    "- **Custom Technical Indicators** for enhanced signal quality\n",
    "- **Risk Management Integration** with position sizing\n",
    "- **Production-Ready Architecture** for live deployment\n",
    "\n",
    "*Note: This demo shows system architecture and capabilities. Proprietary features and specific trading logic are abstracted for IP protection.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📦 System Setup & Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from datetime import datetime, timedelta\n",
    "import yfinance as yf\n",
    "\n",
    "# ML Libraries\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "import xgboost as xgb\n",
    "\n",
    "# Configure visualization\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"🚀 ML Trading System Initialized\")\n",
    "print(f\"📊 Environment Ready - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📊 Market Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Professional data loading with error handling\n",
    "def load_market_data(ticker=\"QQQ\", period_days=365):\n",
    "    \"\"\"\n",
    "    Load market data with robust error handling and validation\n",
    "    \"\"\"\n",
    "    try:\n",
    "        end_date = datetime.now()\n",
    "        start_date = end_date - timedelta(days=period_days)\n",
    "        \n",
    "        print(f\"📥 Loading {ticker} data ({period_days} days)...\")\n",
    "        df = yf.download(ticker, start=start_date, end=end_date, interval=\"1d\")\n",
    "        \n",
    "        # Handle MultiIndex columns from yfinance\n",
    "        if isinstance(df.columns, pd.MultiIndex):\n",
    "            df.columns = [col[0].lower() if isinstance(col, tuple) else col.lower() for col in df.columns]\n",
    "        else:\n",
    "            df.columns = [col.lower() for col in df.columns]\n",
    "        \n",
    "        # Data validation\n",
    "        df = df.dropna()\n",
    "        \n",
    "        print(f\"✅ Data loaded: {len(df)} records\")\n",
    "        print(f\"📅 Period: {df.index[0].date()} to {df.index[-1].date()}\")\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Data loading failed: {e}\")\n",
    "        return None\n",
    "\n",
    "# Load demonstration data\n",
    "df = load_market_data(\"QQQ\", 500)  # NASDAQ ETF for demo\n",
    "\n",
    "if df is not None:\n",
    "    print(f\"\\n📈 Price Summary:\")\n",
    "    print(f\"   Range: ${df['close'].min():.2f} - ${df['close'].max():.2f}\")\n",
    "    print(f\"   Latest: ${df['close'].iloc[-1]:.2f}\")\n",
    "    \n",
    "    # Display sample\n",
    "    df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔧 Advanced Feature Engineering Framework\n",
    "\n",
    "**Professional ML feature extraction pipeline with 50+ indicators:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvancedFeatureExtractor:\n",
    "    \"\"\"\n",
    "    Professional-grade feature extraction for trading systems\n",
    "    Implements market microstructure, technical, and behavioral features\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.scaler = StandardScaler()\n",
    "        print(\"🔧 Advanced Feature Extractor Initialized\")\n",
    "        \n",
    "    def extract_features(self, df):\n",
    "        \"\"\"\n",
    "        Extract comprehensive feature set for ML models\n",
    "        \"\"\"\n",
    "        features = pd.DataFrame(index=df.index)\n",
    "        print(\"⚙️ Extracting ML features...\")\n",
    "        \n",
    "        # === PRICE ACTION FEATURES ===\n",
    "        print(\"   📊 Price action analysis...\")\n",
    "        for period in [5, 10, 20, 50]:\n",
    "            features[f'sma_{period}'] = df['close'].rolling(period).mean()\n",
    "            features[f'price_to_sma_{period}'] = df['close'] / features[f'sma_{period}']\n",
    "            features[f'volatility_{period}'] = df['close'].rolling(period).std()\n",
    "        \n",
    "        # === MOMENTUM INDICATORS ===\n",
    "        print(\"   ⚡ Momentum analysis...\")\n",
    "        for period in [1, 3, 5, 10, 20]:\n",
    "            features[f'return_{period}d'] = df['close'].pct_change(period)\n",
    "            features[f'momentum_{period}'] = (df['close'] - df['close'].shift(period)) / df['close'].shift(period)\n",
    "        \n",
    "        # === VOLUME ANALYSIS ===\n",
    "        print(\"   📈 Volume microstructure...\")\n",
    "        features['volume_sma_20'] = df['volume'].rolling(20).mean()\n",
    "        features['volume_ratio'] = df['volume'] / features['volume_sma_20']\n",
    "        features['price_volume'] = df['close'] * df['volume']\n",
    "        features['volume_trend'] = df['volume'].rolling(5).mean() / df['volume'].rolling(20).mean()\n",
    "        \n",
    "        # === RANGE ANALYSIS ===\n",
    "        print(\"   📏 Range and positioning...\")\n",
    "        for period in [10, 20, 50]:\n",
    "            features[f'high_{period}'] = df['high'].rolling(period).max()\n",
    "            features[f'low_{period}'] = df['low'].rolling(period).min()\n",
    "            features[f'range_{period}'] = features[f'high_{period}'] - features[f'low_{period}']\n",
    "            features[f'position_in_range_{period}'] = (df['close'] - features[f'low_{period}']) / features[f'range_{period}']\n",
    "        \n",
    "        # === ADVANCED TECHNICAL INDICATORS ===\n",
    "        print(\"   🎯 Advanced technical analysis...\")\n",
    "        # Custom RSI implementation\n",
    "        def calculate_rsi(prices, period=14):\n",
    "            delta = prices.diff()\n",
    "            gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()\n",
    "            loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()\n",
    "            rs = gain / loss\n",
    "            return 100 - (100 / (1 + rs))\n",
    "        \n",
    "        features['rsi_14'] = calculate_rsi(df['close'], 14)\n",
    "        features['rsi_7'] = calculate_rsi(df['close'], 7)\n",
    "        \n",
    "        # Bollinger Bands\n",
    "        features['bb_middle'] = df['close'].rolling(20).mean()\n",
    "        features['bb_std'] = df['close'].rolling(20).std()\n",
    "        features['bb_upper'] = features['bb_middle'] + (features['bb_std'] * 2)\n",
    "        features['bb_lower'] = features['bb_middle'] - (features['bb_std'] * 2)\n",
    "        features['bb_position'] = (df['close'] - features['bb_lower']) / (features['bb_upper'] - features['bb_lower'])\n",
    "        \n",
    "        # === MARKET TIMING FEATURES ===\n",
    "        print(\"   ⏰ Temporal pattern analysis...\")\n",
    "        features['day_of_week'] = df.index.dayofweek\n",
    "        features['hour'] = df.index.hour\n",
    "        features['day_of_month'] = df.index.day\n",
    "        \n",
    "        # Cyclical encoding for time features\n",
    "        features['dow_sin'] = np.sin(2 * np.pi * features['day_of_week'] / 7)\n",
    "        features['dow_cos'] = np.cos(2 * np.pi * features['day_of_week'] / 7)\n",
    "        \n",
    "        # === PROPRIETARY FEATURES (ABSTRACTED) ===\n",
    "        print(\"   🔒 Proprietary signal processing...\")\n",
    "        # Note: Actual proprietary features are abstracted for IP protection\n",
    "        features['custom_signal_1'] = np.random.normal(0, 1, len(df))  # Placeholder\n",
    "        features['custom_signal_2'] = np.random.normal(0, 1, len(df))  # Placeholder\n",
    "        features['custom_timing'] = np.random.choice([0, 1], len(df), p=[0.9, 0.1])  # Placeholder\n",
    "        \n",
    "        # === TARGET VARIABLES ===\n",
    "        print(\"   🎯 Target variable creation...\")\n",
    "        for horizon in [1, 5, 10, 20]:\n",
    "            features[f'forward_return_{horizon}'] = df['close'].shift(-horizon) / df['close'] - 1\n",
    "            features[f'target_up_{horizon}'] = (features[f'forward_return_{horizon}'] > 0).astype(int)\n",
    "        \n",
    "        print(f\"✅ Feature extraction complete: {len(features.columns)} features\")\n",
    "        return features.dropna()\n",
    "    \n",
    "    def prepare_ml_data(self, features_df, target_col='forward_return_5'):\n",
    "        \"\"\"\n",
    "        Prepare features and targets for ML training\n",
    "        \"\"\"\n",
    "        # Separate features from targets\n",
    "        feature_cols = [col for col in features_df.columns \n",
    "                       if not col.startswith('forward_return') and not col.startswith('target_up')]\n",
    "        \n",
    "        X = features_df[feature_cols]\n",
    "        y = features_df[target_col]\n",
    "        \n",
    "        # Remove NaN values\n",
    "        valid_idx = ~y.isna()\n",
    "        X = X[valid_idx]\n",
    "        y = y[valid_idx]\n",
    "        \n",
    "        return X, y\n",
    "\n",
    "# Initialize and run feature extraction\n",
    "if df is not None:\n",
    "    extractor = AdvancedFeatureExtractor()\n",
    "    features_df = extractor.extract_features(df)\n",
    "    \n",
    "    print(f\"\\n📊 Feature Engineering Results:\")\n",
    "    print(f\"   Samples: {len(features_df)}\")\n",
    "    print(f\"   Features: {len(features_df.columns)}\")\n",
    "    print(f\"   Date Range: {features_df.index[0].date()} to {features_df.index[-1].date()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🤖 ML Model Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProfessionalMLTrainer:\n",
    "    \"\"\"\n",
    "    Enterprise-grade ML training pipeline for trading systems\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.models = {}\n",
    "        self.feature_importance = {}\n",
    "        print(\"🤖 Professional ML Trainer Initialized\")\n",
    "        \n",
    "    def train_ensemble(self, X, y, task_type='regression'):\n",
    "        \"\"\"\n",
    "        Train ensemble of ML models with time series validation\n",
    "        \"\"\"\n",
    "        print(f\"\\n🚀 Training {task_type} ensemble...\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        # Time series cross-validation\n",
    "        tscv = TimeSeriesSplit(n_splits=5)\n",
    "        \n",
    "        # Model configurations\n",
    "        if task_type == 'regression':\n",
    "            models_config = {\n",
    "                'xgboost': xgb.XGBRegressor(\n",
    "                    n_estimators=100,\n",
    "                    learning_rate=0.1,\n",
    "                    max_depth=6,\n",
    "                    random_state=42,\n",
    "                    verbosity=0\n",
    "                ),\n",
    "                'random_forest': RandomForestRegressor(\n",
    "                    n_estimators=50,\n",
    "                    max_depth=10,\n",
    "                    random_state=42\n",
    "                )\n",
    "            }\n",
    "        else:  # classification\n",
    "            models_config = {\n",
    "                'xgboost': xgb.XGBClassifier(\n",
    "                    n_estimators=100,\n",
    "                    learning_rate=0.1,\n",
    "                    max_depth=6,\n",
    "                    random_state=42,\n",
    "                    verbosity=0\n",
    "                ),\n",
    "                'random_forest': RandomForestClassifier(\n",
    "                    n_estimators=50,\n",
    "                    max_depth=10,\n",
    "                    random_state=42\n",
    "                )\n",
    "            }\n",
    "        \n",
    "        results = {}\n",
    "        for name, model in models_config.items():\n",
    "            print(f\"📈 Training {name}...\")\n",
    "            \n",
    "            try:\n",
    "                # Cross-validation\n",
    "                if task_type == 'regression':\n",
    "                    cv_scores = cross_val_score(model, X, y, cv=tscv, scoring='neg_mean_squared_error')\n",
    "                    score = -cv_scores.mean()\n",
    "                    metric = 'RMSE'\n",
    "                else:\n",
    "                    cv_scores = cross_val_score(model, X, y, cv=tscv, scoring='accuracy')\n",
    "                    score = cv_scores.mean()\n",
    "                    metric = 'Accuracy'\n",
    "                \n",
    "                # Fit final model\n",
    "                model.fit(X, y)\n",
    "                self.models[f\"{task_type}_{name}\"] = model\n",
    "                \n",
    "                # Feature importance\n",
    "                if hasattr(model, 'feature_importances_'):\n",
    "                    importance_dict = dict(zip(X.columns, model.feature_importances_))\n",
    "                    self.feature_importance[f\"{task_type}_{name}\"] = importance_dict\n",
    "                \n",
    "                results[name] = {\n",
    "                    'score': score,\n",
    "                    'std': cv_scores.std(),\n",
    "                    'metric': metric\n",
    "                }\n",
    "                \n",
    "                print(f\"✅ {name}: {metric} = {score:.4f} (±{cv_scores.std():.4f})\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"❌ {name}: Training failed - {str(e)}\")\n",
    "                results[name] = {'score': 0, 'std': 0, 'metric': 'Error'}\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def analyze_features(self, top_n=15):\n",
    "        \"\"\"\n",
    "        Analyze feature importance across models\n",
    "        \"\"\"\n",
    "        if not self.feature_importance:\n",
    "            print(\"No feature importance data available\")\n",
    "            return []\n",
    "        \n",
    "        # Aggregate importance across models\n",
    "        all_importance = {}\n",
    "        for model_name, importance_dict in self.feature_importance.items():\n",
    "            for feature, importance in importance_dict.items():\n",
    "                if feature not in all_importance:\n",
    "                    all_importance[feature] = []\n",
    "                all_importance[feature].append(importance)\n",
    "        \n",
    "        # Average importance\n",
    "        avg_importance = {\n",
    "            feature: np.mean(importances)\n",
    "            for feature, importances in all_importance.items()\n",
    "        }\n",
    "        \n",
    "        # Sort by importance\n",
    "        sorted_features = sorted(avg_importance.items(), key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        print(f\"\\n📊 TOP {top_n} MOST IMPORTANT FEATURES:\")\n",
    "        print(\"=\" * 60)\n",
    "        for i, (feature, importance) in enumerate(sorted_features[:top_n], 1):\n",
    "            print(f\"{i:2d}. {feature:<25} {importance:.4f}\")\n",
    "        \n",
    "        return sorted_features\n",
    "\n",
    "# Train models if features are available\n",
    "if 'features_df' in locals() and not features_df.empty:\n",
    "    # Prepare training data\n",
    "    X, y = extractor.prepare_ml_data(features_df, target_col='forward_return_5')\n",
    "    \n",
    "    print(f\"\\n📋 Training Data Prepared:\")\n",
    "    print(f\"   Samples: {len(X)}\")\n",
    "    print(f\"   Features: {len(X.columns)}\")\n",
    "    print(f\"   Target Mean: {y.mean():.4f}\")\n",
    "    \n",
    "    # Initialize trainer and train models\n",
    "    trainer = ProfessionalMLTrainer()\n",
    "    \n",
    "    # Train regression models\n",
    "    reg_results = trainer.train_ensemble(X, y, task_type='regression')\n",
    "    \n",
    "    # Analyze feature importance\n",
    "    important_features = trainer.analyze_features(top_n=20)\n",
    "    \n",
    "    print(f\"\\n🎉 ML Training Complete!\")\n",
    "else:\n",
    "    print(\"❌ No feature data available for training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📊 Feature Importance Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature importance\n",
    "if 'important_features' in locals() and important_features:\n",
    "    # Get top features for visualization\n",
    "    top_features = important_features[:12]\n",
    "    feature_names = [f[0] for f in top_features]\n",
    "    feature_scores = [f[1] for f in top_features]\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    bars = plt.barh(range(len(feature_names)), feature_scores, color='steelblue')\n",
    "    plt.yticks(range(len(feature_names)), feature_names)\n",
    "    plt.xlabel('Feature Importance')\n",
    "    plt.title('🎯 Top ML Features for Trading System', fontsize=16, fontweight='bold')\n",
    "    plt.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, bar in enumerate(bars):\n",
    "        width = bar.get_width()\n",
    "        plt.text(width + 0.001, bar.get_y() + bar.get_height()/2, \n",
    "                f'{width:.3f}', ha='left', va='center', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n🔍 Feature Analysis Summary:\")\n",
    "    print(f\"   Most Important: {important_features[0][0]} ({important_features[0][1]:.4f})\")\n",
    "    print(f\"   Technical Features: {len([f for f in important_features if any(x in f[0] for x in ['sma', 'rsi', 'bb'])])}\")\n",
    "    print(f\"   Volume Features: {len([f for f in important_features if 'volume' in f[0]])}\")\n",
    "    print(f\"   Timing Features: {len([f for f in important_features if any(x in f[0] for x in ['hour', 'dow', 'custom'])])}\")\n",
    "else:\n",
    "    print(\"⚠️ Feature importance data not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎯 Signal Generation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProfessionalSignalGenerator:\n",
    "    \"\"\"\n",
    "    Production-grade signal generation system\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, trainer):\n",
    "        self.trainer = trainer\n",
    "        self.models = trainer.models\n",
    "        print(\"🎯 Professional Signal Generator Initialized\")\n",
    "    \n",
    "    def generate_ensemble_predictions(self, X, task_type='regression'):\n",
    "        \"\"\"\n",
    "        Generate ensemble predictions from trained models\n",
    "        \"\"\"\n",
    "        predictions = {}\n",
    "        \n",
    "        for model_name, model in self.models.items():\n",
    "            if not model_name.startswith(task_type):\n",
    "                continue\n",
    "            \n",
    "            name = model_name.replace(f\"{task_type}_\", \"\")\n",
    "            \n",
    "            try:\n",
    "                predictions[name] = model.predict(X)\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Model {name} prediction failed: {e}\")\n",
    "        \n",
    "        if not predictions:\n",
    "            return np.zeros(len(X))\n",
    "        \n",
    "        # Simple ensemble average\n",
    "        ensemble_pred = np.zeros(len(X))\n",
    "        for name, pred in predictions.items():\n",
    "            ensemble_pred += pred / len(predictions)\n",
    "        \n",
    "        return ensemble_pred\n",
    "    \n",
    "    def generate_trading_signals(self, features_df, threshold=0.01):\n",
    "        \"\"\"\n",
    "        Generate professional trading signals\n",
    "        \"\"\"\n",
    "        print(f\"🤖 Generating trading signals (threshold: {threshold})...\")\n",
    "        \n",
    "        # Prepare features\n",
    "        feature_cols = [col for col in features_df.columns \n",
    "                       if not col.startswith('forward_return') and not col.startswith('target_up')]\n",
    "        X = features_df[feature_cols]\n",
    "        \n",
    "        # Get predictions\n",
    "        predictions = self.generate_ensemble_predictions(X, task_type='regression')\n",
    "        \n",
    "        # Create signals dataframe\n",
    "        signals = pd.DataFrame(index=features_df.index)\n",
    "        signals['ml_prediction'] = predictions\n",
    "        signals['signal_strength'] = np.abs(predictions)\n",
    "        \n",
    "        # Generate trading signals with risk management\n",
    "        signals['long_signal'] = (\n",
    "            (predictions > threshold) &\n",
    "            (features_df['volume_ratio'] > 1.2) &  # Volume confirmation\n",
    "            (features_df['rsi_14'] < 80)  # Not overbought\n",
    "        )\n",
    "        \n",
    "        signals['short_signal'] = (\n",
    "            (predictions < -threshold) &\n",
    "            (features_df['volume_ratio'] > 1.2) &  # Volume confirmation\n",
    "            (features_df['rsi_14'] > 20)  # Not oversold\n",
    "        )\n",
    "        \n",
    "        # Enhanced signals with proprietary filters (abstracted)\n",
    "        signals['enhanced_long'] = (\n",
    "            signals['long_signal'] &\n",
    "            (features_df['custom_timing'] == 1)  # Proprietary timing (placeholder)\n",
    "        )\n",
    "        \n",
    "        signals['enhanced_short'] = (\n",
    "            signals['short_signal'] &\n",
    "            (features_df['custom_timing'] == 1)  # Proprietary timing (placeholder)\n",
    "        )\n",
    "        \n",
    "        print(f\"✅ Generated {len(signals)} signals\")\n",
    "        return signals\n",
    "\n",
    "# Generate signals if trainer is available\n",
    "if 'trainer' in locals() and 'features_df' in locals():\n",
    "    signal_gen = ProfessionalSignalGenerator(trainer)\n",
    "    signals = signal_gen.generate_trading_signals(features_df, threshold=0.005)\n",
    "    \n",
    "    print(f\"\\n📊 SIGNAL STATISTICS:\")\n",
    "    print(f\"   Total periods: {len(signals)}\")\n",
    "    print(f\"   Long signals: {signals['long_signal'].sum()}\")\n",
    "    print(f\"   Short signals: {signals['short_signal'].sum()}\")\n",
    "    print(f\"   Enhanced long: {signals['enhanced_long'].sum()}\")\n",
    "    print(f\"   Enhanced short: {signals['enhanced_short'].sum()}\")\n",
    "    \n",
    "    # Show sample of enhanced signals\n",
    "    enhanced_signals = signals[signals['enhanced_long'] | signals['enhanced_short']]\n",
    "    if len(enhanced_signals) > 0:\n",
    "        print(f\"\\n📋 SAMPLE ENHANCED SIGNALS:\")\n",
    "        for i, (timestamp, row) in enumerate(enhanced_signals.head(5).iterrows()):\n",
    "            direction = \"LONG\" if row['enhanced_long'] else \"SHORT\"\n",
    "            strength = row['signal_strength']\n",
    "            print(f\"   {i+1}. {timestamp.date()}: {direction:5s} | Strength: {strength:.4f}\")\n",
    "    else:\n",
    "        print(\"\\n💡 No enhanced signals in sample period - adjust threshold for more signals\")\n",
    "else:\n",
    "    print(\"⚠️ Signal generation requires trained models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📈 Performance Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance visualization\n",
    "if 'signals' in locals() and 'df' in locals():\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "    \n",
    "    # 1. Price chart with signals\n",
    "    axes[0,0].plot(df.index, df['close'], label='Price', linewidth=1)\n",
    "    \n",
    "    # Mark long signals\n",
    "    long_signals = signals[signals['enhanced_long']]\n",
    "    if len(long_signals) > 0:\n",
    "        long_prices = [df.loc[idx, 'close'] for idx in long_signals.index if idx in df.index]\n",
    "        axes[0,0].scatter(long_signals.index, long_prices, \n",
    "                         color='green', marker='^', s=50, label='Long Signals', alpha=0.7)\n",
    "    \n",
    "    # Mark short signals  \n",
    "    short_signals = signals[signals['enhanced_short']]\n",
    "    if len(short_signals) > 0:\n",
    "        short_prices = [df.loc[idx, 'close'] for idx in short_signals.index if idx in df.index]\n",
    "        axes[0,0].scatter(short_signals.index, short_prices,\n",
    "                         color='red', marker='v', s=50, label='Short Signals', alpha=0.7)\n",
    "    \n",
    "    axes[0,0].set_title('🎯 ML Trading Signals', fontweight='bold')\n",
    "    axes[0,0].legend()\n",
    "    axes[0,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Signal distribution\n",
    "    signal_hours = [t.hour for t in signals[signals['enhanced_long'] | signals['enhanced_short']].index]\n",
    "    if signal_hours:\n",
    "        axes[0,1].hist(signal_hours, bins=24, alpha=0.7, color='steelblue')\n",
    "        axes[0,1].set_title('⏰ Signal Distribution by Hour')\n",
    "        axes[0,1].set_xlabel('Hour of Day')\n",
    "        axes[0,1].grid(True, alpha=0.3)\n",
    "    else:\n",
    "        axes[0,1].text(0.5, 0.5, 'No signals in sample', ha='center', va='center', transform=axes[0,1].transAxes)\n",
    "        axes[0,1].set_title('⏰ Signal Distribution')\n",
    "    \n",
    "    # 3. Prediction accuracy\n",
    "    axes[1,0].hist(signals['ml_prediction'], bins=30, alpha=0.7, color='orange')\n",
    "    axes[1,0].axvline(0, color='red', linestyle='--', alpha=0.7)\n",
    "    axes[1,0].set_title('🎲 ML Prediction Distribution')\n",
    "    axes[1,0].set_xlabel('Predicted Return')\n",
    "    axes[1,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Signal strength\n",
    "    axes[1,1].plot(signals.index, signals['signal_strength'], alpha=0.7, color='purple')\n",
    "    axes[1,1].set_title('💪 Signal Strength Over Time')\n",
    "    axes[1,1].set_ylabel('Signal Strength')\n",
    "    axes[1,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n📊 System Performance Summary:\")\n",
    "    print(f\"   Average prediction: {signals['ml_prediction'].mean():.4f}\")\n",
    "    print(f\"   Prediction volatility: {signals['ml_prediction'].std():.4f}\")\n",
    "    print(f\"   Signal rate: {(signals['enhanced_long'].sum() + signals['enhanced_short'].sum()) / len(signals) * 100:.1f}%\")\n",
    "    \n",
    "else:\n",
    "    print(\"⚠️ Performance visualization requires signal data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 💾 System Export & Production Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export system for production (demo version)\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "if 'trainer' in locals() and 'signal_gen' in locals():\n",
    "    # Create demo system package\n",
    "    demo_system = {\n",
    "        'version': '1.0.0',\n",
    "        'created': datetime.now().isoformat(),\n",
    "        'description': 'ML Trading System Demo - Professional Implementation',\n",
    "        'models_trained': len(trainer.models),\n",
    "        'features_count': len(X.columns) if 'X' in locals() else 0,\n",
    "        'data_samples': len(features_df) if 'features_df' in locals() else 0,\n",
    "        'config': {\n",
    "            'signal_threshold': 0.005,\n",
    "            'volume_filter': True,\n",
    "            'rsi_bounds': [20, 80],\n",
    "            'ensemble_models': list(trainer.models.keys()) if hasattr(trainer, 'models') else []\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Save demo info (not the actual models for IP protection)\n",
    "    with open('ml_trading_system_demo_info.pkl', 'wb') as f:\n",
    "        pickle.dump(demo_system, f)\n",
    "    \n",
    "    print(\"💾 DEMO SYSTEM EXPORT COMPLETE\")\n",
    "    print(\"=\" * 40)\n",
    "    print(f\"📋 System Version: {demo_system['version']}\")\n",
    "    print(f\"🤖 Models Trained: {demo_system['models_trained']}\")\n",
    "    print(f\"📊 Features: {demo_system['features_count']}\")\n",
    "    print(f\"📈 Data Samples: {demo_system['data_samples']}\")\n",
    "    \n",
    "    print(\"\\n🚀 PRODUCTION DEPLOYMENT NOTES:\")\n",
    "    print(\"=\" * 40)\n",
    "    print(\"✅ Real-time data pipeline integration required\")\n",
    "    print(\"✅ Risk management layer implementation\")\n",
    "    print(\"✅ Position sizing optimization\")\n",
    "    print(\"✅ Performance monitoring dashboard\")\n",
    "    print(\"✅ Model retraining schedule (monthly recommended)\")\n",
    "    print(\"✅ Proprietary features integration (IP protected)\")\n",
    "    \n",
    "    print(\"\\n🔒 IP PROTECTION NOTES:\")\n",
    "    print(\"=\" * 40)\n",
    "    print(\"• Proprietary timing algorithms abstracted\")\n",
    "    print(\"• Specific feature engineering techniques protected\")\n",
    "    print(\"• Model hyperparameters and ensemble weights secured\")\n",
    "    print(\"• Custom indicators and signals anonymized\")\n",
    "    \n",
    "else:\n",
    "    print(\"⚠️ System export requires trained models\")\n",
    "\n",
    "print(\"\\n🎉 ML TRADING SYSTEM DEMO COMPLETE!\")\n",
    "print(\"\\n📝 This demonstration showcases:\")\n",
    "print(\"   • Professional ML pipeline architecture\")\n",
    "print(\"   • Advanced feature engineering capabilities\")\n",
    "print(\"   • Ensemble model training and validation\")\n",
    "print(\"   • Production-ready signal generation\")\n",
    "print(\"   • Comprehensive performance analysis\")\n",
    "print(\"\\n🔐 Proprietary components abstracted for IP protection\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
